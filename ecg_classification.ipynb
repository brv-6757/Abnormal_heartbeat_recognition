{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports and Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError, Huber, CosineSimilarity\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from keras.saving import register_keras_serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    min = np.min(data)\n",
    "    max = np.max(data)\n",
    "    return (data-min)/(max-min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:[], Platform:Windows-11-10.0.26100-SP0, Processor: AMD64\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPU:{tf.config.list_physical_devices('GPU')}, Platform:{platform.platform()}, Processor: {platform.machine()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Utility Functions\n",
    "def predict(model, data):\n",
    "    predictions = model.predict(data)\n",
    "    loss = np.mean(np.abs(data - predictions), axis=1)\n",
    "    return predictions, loss\n",
    "\n",
    "def plot_examples(model, data, ax, title):\n",
    "    pred, loss = predict(model, data)\n",
    "    ax.plot(data.flatten(), label=\"Actual\")\n",
    "    ax.plot(pred[0], label=\"Predicted\")\n",
    "    ax.fill_between(range(1, 189), data.flatten(), pred[0], alpha=0.3, color=\"r\")\n",
    "    ax.legend(shadow=True, frameon=True, facecolor=\"inherit\", loc=1, fontsize=7)\n",
    "    ax.set_title(f\"{title} (loss: {loss[0]:.3f})\", fontsize=9.5)\n",
    "\n",
    "def get_reconstruction_error(model, data):\n",
    "    predictions = model.predict(data)\n",
    "    return np.mean(np.abs(data - predictions), axis=1)\n",
    "\n",
    "def classify_errors(errors, threshold):\n",
    "    return np.array(errors > threshold, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Loading and Pre-processing\n",
    "normal_df = pd.read_csv(\"ptbdb_normal.csv\", sep=',').drop(\"target\", axis=1, errors=\"ignore\")\n",
    "anomaly_df = pd.read_csv(\"ptbdb_abnormal.csv\", sep=',').drop(\"target\", axis=1, errors=\"ignore\")\n",
    "\n",
    "normal = normal_df.to_numpy()\n",
    "anomaly = anomaly_df.to_numpy()\n",
    "X_train, X_test = train_test_split(normal, test_size=0.15, random_state=45, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data.csv\").to_numpy()\n",
    "test = test.transpose()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.read_csv(\"new_data.csv\").to_numpy().transpose()\n",
    "# plt.plot(t1[0])\n",
    "t2 = (t1[0]*3.3)/4095\n",
    "# plt.plot(t2)\n",
    "signals = [t1[0],t2]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "# Plot each signal in the grid\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.plot(signals[i])\n",
    "    ax.set_title(f'Signal {i + 1}')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass_filter(data, cutoff, fs, order=4):\n",
    "    nyquist = 0.5 * fs  # Nyquist frequency\n",
    "    normal_cutoff = cutoff / nyquist  # Normalize the cutoff frequency\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = butter_lowpass_filter(t1[0],20,125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_t2 = butter_lowpass_filter(t2,20,125)\n",
    "plt.plot(fil_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12,6))\n",
    "\n",
    "# Plot on each axis\n",
    "sns.histplot(t2, kde=True, ax=axes[0])\n",
    "sns.histplot(fil_t2, kde=True, ax=axes[1])\n",
    "sns.histplot(normalize(fil_t2), kde=True, ax=axes[2])\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_norm = normalize(t2)\n",
    "sns.histplot(t2_norm,kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Plot on each axis\n",
    "sns.histplot(normal[0], kde=True, ax=axes[0, 0])\n",
    "sns.histplot(normal[1], kde=True, ax=axes[0, 1])\n",
    "sns.histplot(normal[2], kde=True, ax=axes[1, 0])\n",
    "sns.histplot(normal[3], kde=True, ax=axes[1, 1])\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_to_plot = anomaly[21:30]\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "\n",
    "# Plot each signal in the grid\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.plot(signals_to_plot[i])\n",
    "    ax.set_title(f'Signal {i + 1}')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "class AutoEncoder(Model):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(AutoEncoder, self).__init__() #inheritance\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(input_dim,)),\n",
    "            layers.Reshape((input_dim, 1)),  # Reshape to 3D for Conv1D\n",
    "            layers.Conv1D(32, 3, strides=1, activation='relu', padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling1D(2, padding=\"same\"),\n",
    "            layers.Conv1D(latent_dim, 3, strides=1, activation='relu', padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling1D(2, padding=\"same\"),\n",
    "        ])\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Conv1D(latent_dim, 3, strides=1, activation='relu', padding=\"same\"),\n",
    "            layers.UpSampling1D(2),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv1D(32, 3, strides=1, activation='relu', padding=\"same\"),\n",
    "            layers.UpSampling1D(2),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(input_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, X):\n",
    "        encoded = self.encoder(X)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[-1]\n",
    "latent_dim = 16\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "early_stopping = EarlyStopping(patience=10, min_delta=1e-3, monitor=\"val_loss\", restore_best_weights=True)\n",
    "loss_functions = {'MAE': MeanAbsoluteError(), 'MSE': MeanSquaredError(), 'Huber': Huber(), 'CosineSimilarity': CosineSimilarity()}\n",
    "best_loss = float('inf')\n",
    "best_model = None\n",
    "best_loss_function = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth for validation\n",
    "y_true_normal = np.zeros(len(X_test))\n",
    "y_true_anomaly = np.ones(len(anomaly))\n",
    "y_test = np.concatenate([y_true_normal, y_true_anomaly])\n",
    "X_combined_test = np.concatenate([X_test, anomaly])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = AutoEncoder(input_dim, latent_dim)\n",
    "# m1.build((None, input_dim))\n",
    "m1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss=Huber())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m188\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m188\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m188\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m94\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m94\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │         \u001b[38;5;34m1,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m94\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,872</span> (7.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,872\u001b[0m (7.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,776</span> (6.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,776\u001b[0m (6.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> (384.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m96\u001b[0m (384.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)    │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling1d (\u001b[38;5;33mUpSampling1D\u001b[0m)    │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling1d_1 (\u001b[38;5;33mUpSampling1D\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m1.encoder.summary()\n",
    "m1.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.fit(X_train, X_train, epochs=epochs, batch_size=batch_size,\n",
    "              validation_split=0.1, callbacks=[early_stopping], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = get_reconstruction_error(m1, X_train)\n",
    "threshold = np.percentile(train_errors, 95)  # 95th percentile as threshold\n",
    "val_errors = get_reconstruction_error(m1, X_combined_test)\n",
    "y_pred_val = np.array(val_errors > threshold, dtype=int)\n",
    "accuracy = accuracy_score(y_test, y_pred_val)\n",
    "print(f\"Validation Accuracy using : {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_array = np.append(fil_t2,[0 for i in range(89)])\n",
    "ts_norm = normalize(testing_array)\n",
    "sns.histplot(ts_norm,kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_norm = ts_norm.reshape((1,188))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(np.append(t2_norm,[0 for i in range(89)]),kde=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = get_reconstruction_error(m1,np.append(t2_norm,[0 for i in range(89)]).reshape((1,188)))\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.percentile(get_reconstruction_error(m1, X_train), 95)\n",
    "print(threshold)\n",
    "pred = classify_errors(error,threshold)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"samples.csv\",header=None).to_numpy().transpose().reshape((8,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.append(normalize(data[0]),[0 for i in range(88)]).reshape((1,188)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    print(get_reconstruction_error(m1,np.append(normalize(data[i]),[0 for i in range(88)]).reshape((1,188))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models for each loss function\n",
    "for name, loss_function in loss_functions.items():\n",
    "    # Define and compile the model\n",
    "    model = AutoEncoder(input_dim, latent_dim)\n",
    "    # model.build((None, input_dim))\n",
    "    # Check if the machine is using an M1/M2 processor\n",
    "    # if \"macOS-13.5.2-arm64-arm-64bit\" in platform.platform() and \"arm64\" in platform.machine():\n",
    "    #     model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.01), loss=loss_function)\n",
    "    #     print(\"Using legacy optimizer for M1/M2 Mac.\")\n",
    "    # elif tf.config.list_physical_devices('GPU'):  # Check if there are any GPUs available\n",
    "    #     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss=loss_function)\n",
    "    #     print(\"Using standard optimizer for GPU.\")\n",
    "    # else:\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss=loss_function)\n",
    "    # print(\"Using standard optimizer for conventional CPU.\")\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, X_train, epochs=epochs, batch_size=batch_size,\n",
    "              validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Calculate the threshold based on the training data\n",
    "    train_errors = get_reconstruction_error(model, X_train)\n",
    "    threshold = np.percentile(train_errors, 95)  # 95th percentile as threshold\n",
    "\n",
    "    # Evaluate the model on combined validation data (normal + anomaly) using the calculated threshold\n",
    "    val_errors = get_reconstruction_error(model, X_combined_test)\n",
    "    y_pred_val = np.array(val_errors > threshold, dtype=int)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred_val)\n",
    "\n",
    "    print(f\"Validation Accuracy using {name}: {accuracy:.2%}\")\n",
    "    print(f\"Validation Reconstruction Error using {name}: {np.mean(val_errors)}\")\n",
    "\n",
    "    # After training, visualize the reconstructions for this specific model\n",
    "    # fig, axes = plt.subplots(2, 5, sharey=True, sharex=True, figsize=(12, 6))\n",
    "    # random_indexes = np.random.randint(0, len(X_train), size=5)\n",
    "    # for i, idx in enumerate(random_indexes):\n",
    "    #     data = X_train[[idx]]\n",
    "    #     plot_examples(model, data, ax=axes[0, i], title=\"Normal\")\n",
    "    # for i, idx in enumerate(random_indexes):\n",
    "    #     data = anomaly[[idx]]\n",
    "    #     plot_examples(model, data, ax=axes[1, i], title=\"Anomaly\")\n",
    "    # plt.tight_layout()\n",
    "    # fig.suptitle(f\"Sample plots for {name} loss (Actual vs Reconstructed by the CNN autoencoder)\", y=1.04, weight=\"bold\")\n",
    "    # plt.show()\n",
    "\n",
    "    # Check if current model is the best\n",
    "    if np.mean(val_errors) < best_loss:\n",
    "        best_loss = np.mean(val_errors)\n",
    "        best_model = model\n",
    "        best_loss_function = name\n",
    "\n",
    "print(f\"Best Model uses {best_loss_function} with average validation error: {best_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluation\n",
    "threshold = np.percentile(get_reconstruction_error(best_model, X_train), 95)\n",
    "normal_errors = get_reconstruction_error(best_model, X_test)\n",
    "anomaly_errors = get_reconstruction_error(best_model, anomaly)\n",
    "y_pred_normal = classify_errors(normal_errors, threshold)\n",
    "y_pred_anomaly = classify_errors(anomaly_errors, threshold)\n",
    "y_true_normal = np.zeros_like(y_pred_normal)\n",
    "y_true_anomaly = np.ones_like(y_pred_anomaly)\n",
    "y_pred = np.concatenate([y_pred_normal, y_pred_anomaly])\n",
    "y_true = np.concatenate([y_true_normal, y_true_anomaly])\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(f\"Threshold: {threshold}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    print(get_reconstruction_error(best_model,np.append(normalize(data[i]),[0 for i in range(88)]).reshape((1,188))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\n",
    "plt.ylabel('Actual Class')\n",
    "plt.xlabel('Predicted Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
